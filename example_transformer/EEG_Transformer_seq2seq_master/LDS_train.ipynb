{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BpTX2z9zXjMo","executionInfo":{"status":"ok","timestamp":1688350962338,"user_tz":-480,"elapsed":20261,"user":{"displayName":"Long WU","userId":"09414210733761439327"}},"outputId":"79721b39-60c1-4896-b25c-a4af6278ff34"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/google\\ colab/EEG-Transformer-seq2seq-master"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9jq8SM_PWmQW","executionInfo":{"status":"ok","timestamp":1688350998259,"user_tz":-480,"elapsed":359,"user":{"displayName":"Long WU","userId":"09414210733761439327"}},"outputId":"4f4b2199-0d61-4c94-87e9-661c14d75cf2"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/google colab/EEG-Transformer-seq2seq-master\n"]}]},{"cell_type":"code","source":["pip install cython"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uKQltaOBa7Pe","executionInfo":{"status":"ok","timestamp":1688351010363,"user_tz":-480,"elapsed":7874,"user":{"displayName":"Long WU","userId":"09414210733761439327"}},"outputId":"d2bf6df1-6de8-4228-c55f-01219b4100bc"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (0.29.35)\n"]}]},{"cell_type":"code","source":["!git clone git@github.com:slinderman/pypolyagamma.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PldGVZE8jq5s","executionInfo":{"status":"ok","timestamp":1688351078066,"user_tz":-480,"elapsed":527,"user":{"displayName":"Long WU","userId":"09414210733761439327"}},"outputId":"cceb518a-99d3-4593-e736-2c6f960d7683"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'pypolyagamma'...\n","Host key verification failed.\r\n","fatal: Could not read from remote repository.\n","\n","Please make sure you have the correct access rights\n","and the repository exists.\n"]}]},{"cell_type":"code","source":["pip install pypolyagamma==1.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZDPi5hj2ZkQv","executionInfo":{"status":"ok","timestamp":1688348765853,"user_tz":-480,"elapsed":27195,"user":{"displayName":"Long WU","userId":"09414210733761439327"}},"outputId":"268a9c46-6063-4cc3-d270-44b85e73b57f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pypolyagamma==1.2\n","  Downloading pypolyagamma-1.2.tar.gz (221 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/221.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m215.0/221.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.2/221.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pypolyagamma==1.2) (1.22.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pypolyagamma==1.2) (1.10.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pypolyagamma==1.2) (3.7.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pypolyagamma==1.2) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pypolyagamma==1.2) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pypolyagamma==1.2) (4.40.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pypolyagamma==1.2) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pypolyagamma==1.2) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pypolyagamma==1.2) (8.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pypolyagamma==1.2) (3.1.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pypolyagamma==1.2) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->pypolyagamma==1.2) (1.16.0)\n","Building wheels for collected packages: pypolyagamma\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Building wheel for pypolyagamma (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for pypolyagamma\u001b[0m\u001b[31m\n","\u001b[0m\u001b[?25h  Running setup.py clean for pypolyagamma\n","Failed to build pypolyagamma\n","\u001b[31mERROR: Could not build wheels for pypolyagamma, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["pip install pylds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YCZ9JQJRWvaj","executionInfo":{"status":"ok","timestamp":1688348155419,"user_tz":-480,"elapsed":25155,"user":{"displayName":"Long WU","userId":"09414210733761439327"}},"outputId":"4c94f9f4-f5fa-4985-dacf-44f8bd360fcd"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pylds\n","  Using cached pylds-0.0.5-cp310-cp310-linux_x86_64.whl\n","Requirement already satisfied: numpy>=1.9.3 in /usr/local/lib/python3.10/dist-packages (from pylds) (1.22.4)\n","Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.10/dist-packages (from pylds) (1.10.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pylds) (3.7.1)\n","Collecting pybasicbayes (from pylds)\n","  Using cached pybasicbayes-0.2.2-cp310-cp310-linux_x86_64.whl\n","Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pylds) (1.6.1)\n","Collecting pypolyagamma>=1.1 (from pylds)\n","  Using cached pypolyagamma-1.2.3.tar.gz (151 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd->pylds) (0.18.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pylds) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pylds) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pylds) (4.40.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pylds) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pylds) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pylds) (8.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pylds) (3.1.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pylds) (2.8.2)\n","Collecting nose (from pybasicbayes->pylds)\n","  Using cached nose-1.3.7-py3-none-any.whl (154 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->pylds) (1.16.0)\n","Building wheels for collected packages: pypolyagamma\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Building wheel for pypolyagamma (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for pypolyagamma\u001b[0m\u001b[31m\n","\u001b[0m\u001b[?25h  Running setup.py clean for pypolyagamma\n","Failed to build pypolyagamma\n","\u001b[31mERROR: Could not build wheels for pypolyagamma, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":347},"id":"JUBtgHdTVrLz","executionInfo":{"status":"error","timestamp":1688348044996,"user_tz":-480,"elapsed":1760,"user":{"displayName":"Long WU","userId":"09414210733761439327"}},"outputId":"69a91c6b-a2a7-4b87-bc1a-f8f04b5bd03a"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-8e6def707ad4>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# various methods to perform bayesian inference on GLDSs.DefaultLDS (see the cell below) implements a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# general purpose linear dynamical system with gaussian noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpylds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDefaultLDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pylds'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["# importing dependencies\n","from lib.eeg_transformer import *\n","from lib.train import *\n","\n","# PyLDS is a Python library for gaussian linear dynamical systems (GLDS) PyLDS also implements\n","# various methods to perform bayesian inference on GLDSs.DefaultLDS (see the cell below) implements a\n","# general purpose linear dynamical system with gaussian noise\n","from pylds.models import DefaultLDS"]},{"cell_type":"markdown","source":["# New Section"],"metadata":{"id":"a7B9nzjDWIix"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RgTnXwU1VrL4"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","# torch.nn is a module that implements varios useful functions and functors to implement flexible and highly\n","# customized neural networks. We will use nn to define neural network modules, different kinds of layers and\n","# diffrent loss functions\n","import torch.nn as nn\n","# torch.nn.functional implements a large variety of activation functions and functional forms of different\n","# neural network layers. Here we will use it for activation functions.\n","import torch.nn.functional as F\n","# torch is the Linear Algebra / Neural Networks library\n","import torch\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","# Seed the random number generators for reproducible results\n","npr.seed(0)\n","torch.manual_seed(1)\n","torch.cuda.manual_seed_all(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-BE8GQOpVrL5"},"outputs":[],"source":["TIMESTEPS = 300 # number of steps in time\n","INSTS = 1000 # batch-size or the number of instances\n","DOBS = 10 # number of observable variables\n","DLAT = 2 # number of hidden variabkes (latent states)\n","\n","def simple_lds(d_observed=DOBS,d_latent=DLAT,d_input=-1,timesteps=TIMESTEPS,insts=INSTS):\n","    ## d_observed : dimensionality of observed data\n","    ## d_latent : dimensionality of latent states\n","    ## d_input : dimensionality of input data. For d_input=-1 a model with no input is generated\n","    ## timesteps: number of simulated timesteps\n","    ## insts: number of instances\n","    ## instantiating an lds with a random rotational dynamics matrix\n","\n","    if d_input == -1 :\n","        lds_model = DefaultLDS(d_observed,d_latent,0)\n","        input_data = None\n","    else:\n","        lds_model = DefaultLDS(d_observed,d_latent,d_input)\n","        input_data = npr.randn(insts,timesteps,d_input)\n","\n","    # initializing the output matrices:\n","    training_set = np.zeros((insts, timesteps, d_observed))\n","    latent_states= np.zeros((insts, timesteps, d_latent))\n","\n","    # running the model and generating data\n","    for i in range(insts):\n","        training_set[i,:,:], latent_states[i,:,:] = lds_model.generate(timesteps, inputs=input_data)\n","    return training_set, latent_states, lds_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SWl-7QvhVrL6"},"outputs":[],"source":["# Instantiating a Model and Generating Data\n","ts,ls,mdl = simple_lds()\n","\n","# Get input_d, output_d, timesteps from the initial dataset\n","input_d, output_d = ts.shape[2], ls.shape[2]\n","timesteps = ts.shape[1]\n","print('input_d:',input_d,'output_d:',output_d,'timesteps:',timesteps)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ujfwHM5VrL7"},"outputs":[],"source":["class LDSDataset(Dataset):\n","    # use boolen value to indicate that the data is for training or testing\n","    def __init__(self,x,y,train,ratio):\n","        self.len = x.shape[0]\n","        self.ratio = ratio\n","        split = int(self.len*self.ratio)\n","        self.x_train = torch.from_numpy(x[:split])\n","        self.y_train = torch.from_numpy(y[:split])\n","        self.x_test = torch.from_numpy(x[split:])\n","        self.y_test = torch.from_numpy(y[split:])\n","        self.train = train\n","\n","    def __len__(self):\n","        if self.train:\n","            return int(self.len*self.ratio)\n","        else:\n","            return int(self.len*(1-self.ratio))\n","\n","    def __getitem__(self, index):\n","        if self.train:\n","            return self.x_train[index], self.y_train[index]\n","        else:\n","            return self.x_test[index], self.y_test[index]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6-VaM5SiVrL7"},"outputs":[],"source":["# split training and testing set\n","split_ratio = 0.8\n","batch_size = 50\n","dataset_train = LDSDataset(ts,ls,True,split_ratio)\n","dataloader_train = DataLoader(dataset=dataset_train,batch_size=batch_size,shuffle=True)\n","dataset_test = LDSDataset(ts,ls,False,split_ratio)\n","dataloader_test = DataLoader(dataset=dataset_test,batch_size=batch_size,shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H3WaHL4sVrL8"},"outputs":[],"source":["opt = {}\n","opt['Transformer-layers'] = 2\n","opt['Model-dimensions'] = 256\n","opt['feedford-size'] = 512\n","opt['headers'] = 8\n","opt['dropout'] = 0.1\n","opt['src_d'] = input_d # input dimension\n","opt['tgt_d'] = output_d # output dimension\n","opt['timesteps'] = timesteps"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hGODHuFXVrL8"},"outputs":[],"source":["criterion = nn.MSELoss() # mean squared error\n","# setup model using hyperparameters defined above\n","model = make_model(opt['src_d'],opt['tgt_d'],opt['Transformer-layers'],opt['Model-dimensions'],opt['feedford-size'],opt['headers'],opt['dropout'])\n","# setup optimization function\n","model_opt = NoamOpt(model_size=opt['Model-dimensions'], factor=1, warmup=400,\n","        optimizer = torch.optim.Adam(model.parameters(), lr=0.015, betas=(0.9, 0.98), eps=1e-9))\n","total_epoch = 2000\n","train_losses = np.zeros(total_epoch)\n","test_losses = np.zeros(total_epoch)\n","\n","for epoch in range(total_epoch):\n","    model.train()\n","    train_loss = run_epoch(data_gen(dataloader_train), model,\n","              SimpleLossCompute(model.generator, criterion, model_opt))\n","    train_losses[epoch]=train_loss\n","\n","    if (epoch+1)%10 == 0:\n","        torch.save({\n","                    'epoch': epoch,\n","                    'model_state_dict': model.state_dict(),\n","                    'optimizer_state_dict': model_opt.optimizer.state_dict(),\n","                    'loss': train_loss,\n","                    }, 'model_checkpoint/'+str(epoch)+'.pth')\n","        torch.save(model, 'model_save/model%d.pth'%(epoch)) # save the model\n","\n","    model.eval() # test the model\n","    test_loss = run_epoch(data_gen(dataloader_test), model,\n","            SimpleLossCompute(model.generator, criterion, None))\n","    test_losses[epoch] = test_loss\n","    print('Epoch[{}/{}], train_loss: {:.6f},test_loss: {:.6f}'.format(epoch+1, total_epoch, train_loss, test_loss))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8-ZW5yAbVrL9"},"outputs":[],"source":["# choose a pair of data from test dataset\n","# transfer from tensor to numpy array\n","test_x, test_y = dataset_test.x_test[1].numpy(),dataset_test.y_test[1].numpy()\n","# make a prediction then compare it with its true output\n","test_out, true_out = output_prediction(model,test_x, test_y, max_len=opt['timesteps'], start_symbol=1,output_d=opt['tgt_d'])"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2"},"colab":{"provenance":[],"gpuType":"T4"}},"nbformat":4,"nbformat_minor":0}