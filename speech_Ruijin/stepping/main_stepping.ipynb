{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1CCzfIRvj6aIV6nMy3UgietFyoy6XRURu","authorship_tag":"ABX9TyPbl15hvCCtrXAXfEB4zjy0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WmNNe5ZSKPHK","executionInfo":{"status":"ok","timestamp":1690624665593,"user_tz":-480,"elapsed":14,"user":{"displayName":"Long WU","userId":"09414210733761439327"}},"outputId":"02108258-fe32-400b-b501-fcd3fa20dd2e"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/python\n"]}],"source":["%cd /content/drive/MyDrive/python"]},{"cell_type":"code","source":["import os\n","os.getcwd()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"RtW-6ax4MrgU","executionInfo":{"status":"ok","timestamp":1690624665594,"user_tz":-480,"elapsed":13,"user":{"displayName":"Long WU","userId":"09414210733761439327"}},"outputId":"ac322237-944f-419e-85f9-5413f60f3339"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/python'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["%%capture\n","! pip install hdf5storage\n","! pip install mne==0.23.0\n","! pip install torch\n","! pip install PIL\n","! pip install tensorboardX\n","! pip install tqdm\n","! pip install pynwb==2.3.2"],"metadata":{"id":"negfauzYKYWj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import io\n","import sys\n","import socket\n","import PIL\n","from torchvision.transforms import ToTensor\n","from tqdm import tqdm\n","from gesture.models.d2l_resnet import d2lresnet\n","from speech_Ruijin.stepping.dataset import dataset_stepping\n","from speech_Ruijin.stepping.model_stepping import model\n","if socket.gethostname() == 'workstation':\n","    sys.path.extend(['C:/Users/wuxiaolong/mydrive/python'])\n","elif socket.gethostname() == 'LongsMac':\n","    sys.path.extend(['/Users/long/My Drive/python'])\n","elif socket.gethostname() == 'DESKTOP-NP9A9VI':\n","    sys.path.extend(['C:/Users/xiaol/My Drive/python/'])\n","from datetime import datetime\n","import pytz\n","from speech_Ruijin.config import *\n","from common_dl import *\n","from torch.utils.data import DataLoader\n","from speech_Ruijin.dataset import dataset_Dutch\n","#from torch.utils.tensorboard import SummaryWriter\n","from tensorboardX import SummaryWriter\n","set_random_seeds(999)\n","\n"],"metadata":{"id":"F1WBsvlkKd0H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","dataname='SingleWordProductionDutch'\n","sid=3\n","mel_bins=23\n","sf_EEG=1024\n","\n","if dataname=='SingleWordProductionDutch':\n","    pt_folder='sub-' + f\"{sid:02d}\"\n","else:\n","    pt_folder='sid'+str(sid)\n","\n","resume=False\n","testing=False\n","the_time=datetime.now(pytz.timezone('Asia/Shanghai'))\n","print(\"Testing: \"+str(testing)+\".\")\n","if testing or debugging:\n","    batch_size = 3\n","    wind_size = 200\n","    stride = 400\n","    epoch_num = 1\n","    patients = 2\n","    result_dir = data_dir + dataname + '/stepping/' + pt_folder + '/stepping_win_' + str(wind_size) + '_stride_' + str(\n","        stride) + '/' + the_time.strftime('%Y_%m_%d') + '_' + the_time.strftime('%H_%M') + '_testing/'\n","else:\n","    batch_size=128\n","    wind_size = 200\n","    stride = 3\n","    epoch_num = 300\n","    patients = 20\n","    result_dir = data_dir + dataname + '/stepping/' + pt_folder + '/stepping_win_' + str(wind_size) + '_stride_' + str(\n","        stride) + '/' + the_time.strftime('%Y_%m_%d') + '_' + the_time.strftime('%H_%M') + '/'\n","\n","if not os.path.exists(result_dir):\n","    print('Result_dir: '+result_dir+'.')\n","    os.makedirs(result_dir)\n","writer = SummaryWriter(result_dir)"],"metadata":{"id":"7YT1KOrVNCDN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["stride=10\n","shift=None #0.03 # -0.03:left shift 30 ms; -30/-60/-90/\n","#def dataset_stepping(dataname='mydata', sid=1,session=None, pt=1, wind_size=200,stride=1,mel_bins=23,val_len=4000,test_len=4000,shift=None):\n","train_ds, val_ds, test_ds = dataset_stepping(dataname=dataname,sid=sid,wind_size=wind_size,stride=stride, mel_bins=mel_bins,shift=shift)\n","# below will read from open dataset\n","# best is sid=3,4,6,8,9,10\n","#train_ds, val_ds, test_ds = dataset_Dutch(dataset_name='SingleWordProductionDutch',sid=4,wind_size=wind_size,stride=stride, mel_bins=mel_bins,val_len=4000,test_len=4000,stepping=True)\n","# Or test on another SEEG audio dataset,sid=[1(mel result looks good),2(TBD),3(TBD)]\n","#train_ds, val_ds, test_ds = dataset_Dutch(dataset_name='stereoEEG2speech_master',sid=1,highgamma=highgamma,wind_size=wind_size,stride=stride, mel_bins=mel_bins,val_len=4000,test_len=4000)\n","\n","train_size=len(train_ds)\n","val_size=len(val_ds)\n","test_size=len(test_ds)\n","print('Train size: '+str(train_size)+', val size: '+str(val_size)+', test size: '+str(test_size)+'.')\n","train_loader = DataLoader(dataset=train_ds, batch_size=batch_size, shuffle=False, pin_memory=False)\n","val_loader = DataLoader(dataset=val_ds, batch_size=batch_size, shuffle=False, pin_memory=False)\n","test_loader = DataLoader(dataset=test_ds, batch_size=batch_size, shuffle=False, pin_memory=False)\n"],"metadata":{"id":"DUzhHMg_4L5F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["learning_rate=0.005\n","ch_num=train_ds[0][0].shape[0]\n","dropout=0.5\n","#net=model(1000,ch_num,wind_size,6,6,dropout,mel_bins)\n","net=d2lresnet(task='regression',reg_d=mel_bins)\n","net=net.to(device)\n","#optimizer = torch.optim.AdamW(net.parameters(), lr=learning_rate)\n","optimizer = torch.optim.Adagrad(net.parameters(), lr=learning_rate,weight_decay=1e-4)\n","loss_fun = nn.MSELoss()"],"metadata":{"id":"C-r9j47e4Prq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resume_epoch=0\n","fig,ax=plt.subplots(2,1, figsize=(10,20))\n","train_losses=[]\n","val_losses=[]\n","for epoch in tqdm(range(epoch_num)):\n","    epoch=epoch+resume_epoch\n","    print('Training on sid: '+str(sid)+'; Epoch:'+str(epoch)+'.')\n","    net.train()\n","    y_preds=[]\n","    running_loss = 0.0\n","    for batch, (x, y) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        x=x.float().to(device)\n","        y=y.float().to(device)\n","        y_pred= net(x) # x:torch.Size([3 batch, 118channel, 200time])\n","        loss = loss_fun(y_pred,y) # y: torch.Size([3, 80])\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item() * x.shape[0]\n","        if batch==len(train_loader)-2:\n","            plot_y=y\n","            plot_y_pred=y_pred\n","        if testing:\n","            break\n","    train_loss = running_loss / train_size\n","    train_losses.append(train_loss)\n","    #show_batch=min(60,y.shape[0])\n","    ax[0].imshow(plot_y.cpu().numpy().squeeze().transpose(), cmap='RdBu_r',aspect='auto')\n","    ax[1].imshow(plot_y_pred.cpu().detach().numpy().squeeze().transpose(), cmap='RdBu_r',aspect='auto')\n","    fig.tight_layout()\n","    buf = io.BytesIO()\n","    plt.savefig(buf, format='jpeg')\n","    buf.seek(0)\n","    image = PIL.Image.open(buf)\n","    image = ToTensor()(image).unsqueeze(0)\n","    writer.add_image('Image/train', image[0], epoch)\n","    ax[0].clear()\n","    ax[1].clear()\n","\n","    print('Evaluating....')\n","    running_loss = 0.0\n","    outputs = []\n","    if epoch % 1 == 0:\n","        net.eval()\n","        with torch.no_grad():\n","            for batch, (val_x, val_y) in enumerate(val_loader):\n","                val_x=val_x.float().to(device)\n","                val_y=val_y.float().to(device)\n","                y_pred = net(val_x)  # x:torch.Size([3 batch, 118channel, 200time])\n","                loss = loss_fun(y_pred, val_y)  # y: torch.Size([3, 80])\n","\n","                running_loss += loss.item() * val_x.shape[0]\n","                if batch==len(val_loader)-2:\n","                    plot_valy=val_y\n","                    plot_valy_pred=y_pred\n","            if testing:\n","                break\n","            val_loss = running_loss / val_size\n","            val_losses.append(val_loss)\n","        print(\"Training loss:{:.2f}; Evaluation loss:{:.2f}.\".format(train_loss, val_loss))\n","    ax[0].imshow(plot_valy.cpu().numpy().squeeze().transpose(), cmap='RdBu_r',aspect='auto')\n","    ax[1].imshow(plot_valy_pred.cpu().detach().numpy().squeeze().transpose(), cmap='RdBu_r',aspect='auto')\n","    fig.tight_layout()\n","    buf = io.BytesIO()\n","    plt.savefig(buf, format='jpeg')\n","    buf.seek(0)\n","    image = PIL.Image.open(buf)\n","    image = ToTensor()(image).unsqueeze(0)\n","    writer.add_image('Image/val', image[0], epoch)\n","    ax[0].clear()\n","    ax[1].clear()\n","\n","    if epoch==resume_epoch:\n","        best_epoch=resume_epoch\n","        best_loss=val_loss\n","        patient=patients\n","        best_model = {\n","            'net': net.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","            'epoch': epoch,\n","            # 'loss': epoch_loss\n","        }\n","    else:\n","        if val_loss<best_loss:\n","            best_epoch=epoch\n","            best_loss=val_loss\n","            patient=patients\n","            best_model = {\n","                'net': net.state_dict(),\n","                'optimizer': optimizer.state_dict(),\n","                'epoch': epoch,\n","                #'loss': epoch_loss\n","            }\n","\n","        else:\n","            patient=patient-1\n","    print(\"patients left: {:d}\".format(patient))\n","    if patient==0:\n","        break\n","    if testing:\n","        #pass # test through all epochs\n","        break\n","\n","filename=result_dir+'best_model_epoch'+str(best_model['epoch'])+'.pth'\n","torch.save(best_model,filename)\n"],"metadata":{"id":"2LlWF_m04S2l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kz6TGVl-FEPh"},"execution_count":null,"outputs":[]}]}