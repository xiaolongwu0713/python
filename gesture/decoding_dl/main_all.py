import sys
import socket
if socket.gethostname() == 'workstation':
    sys.path.extend(['C:/Users/wuxiaolong/mydrive/python'])
elif socket.gethostname() == 'LongsMac':
    sys.path.extend(['/Users/long/My Drive/python'])
elif socket.gethostname() == 'DESKTOP-NP9A9VI':
    sys.path.extend(['C:/Users/xiaol/My Drive/python/'])
elif socket.gethostname() == 'Long': # Yoga
    sys.path.extend(['D:/mydrive/python/'])


from torch.optim import lr_scheduler
import matplotlib.pyplot as plt
from braindecode.models import ShallowFBCSPNet,EEGNetv4,Deep4Net
from gesture.channel_selection.utils import get_good_sids, get_final_good_sids, get_selected_channel_gumbel,get_selected_channel_stg
from gesture.channel_selection.mannal_selection import mannual_selection
from gesture.utils import *
from gesture.models.deepmodel import deepnet,deepnet_seq,deepnet_rnn, deepnet_da,deepnet_changeDepth,deepnet_expandPlan
from gesture.models.d2l_resnet import d2lresnet
from gesture.models.deepmodel import TSception2
from gesture.config import *
from gesture.preprocess.chn_settings import get_channel_setting

seed = 20200220  # random seed to make results reproducible
set_random_seeds(seed=seed)
cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it
device = 'cuda' if cuda else 'cpu'
if cuda:
    torch.backends.cudnn.benchmark = True

#if 'PYTHONPATH' in os.environ and 'PyCharm' in os.environ['PYTHONPATH']:
if os.environ.get('PYCHARM_HOSTED'):
    running_from_IDE=True
    running_from_CMD = False
    print("Running from IDE.")
else:
    running_from_CMD = True
    running_from_IDE = False
    print("Running from CMD.")

if running_from_CMD: # run from cmd on workstation
    if socket.gethostname() == 'Long' or socket.gethostname() == 'DESKTOP-NP9A9VI':
        sid = int(float(sys.argv[1]))
        model_name = sys.argv[2]

        try:
            train_mode = sys.argv[3] # with_selected_channels/DA
        except IndexError:
            train_mode = False
        if train_mode=='DA':
            try:
                method = sys.argv[4] #'gumble'/'stg'/'mannual' or 'VAE'/'GAN'/'CWGANGP'
            except IndexError:
                method = False
            try:
                cv=int(sys.argv[5])
            except IndexError:
                cv=None
        elif train_mode=='original':
            cv = int(sys.argv[4])
else: # run from IDE
    sid=2
    model_name = 'deepnet'
    train_mode='original' #'DA'/original/'selected_channels'
    method='cTGAN' # 'NI'/'VAE'/'CWGANGP'/
    cv=1
class_number=5
fs=1000
wind = 500
stride = 200
#from gesture.config import time_stamps,ckpt_epochs


gen_data_all=None
if train_mode=='selected_channels':
    print("Python: re-train using the selected channels.")
    # selected channels
    if method == 'gumbel':
        channel_num_selected = 10
        selected_channels, acc = get_selected_channel_gumbel(sid, channel_num_selected)
        result_path = result_dir + 'deepLearning/retrain/' + method + '/P' + str(sid) + '/'
    elif method == 'stg':
        channel_number=9999
        selected_channels, acc,_ = get_selected_channel_stg(sid, channel_number)
        selected_channels = selected_channels.tolist()
        if channel_number > 999:
            result_path = result_dir + 'deepLearning/retrain/' + method + '/all_selected/P' + str(sid) + '/'
        else:
            result_path = result_dir + 'deepLearning/retrain/' + method + '/'+str(channel_number)+'channels/P' + str(sid) + '/'
    elif method == 'manual':
        selected_channels=mannual_selection['P'+str(sid)][:10] #first 10 channels
        result_path = result_dir + 'deepLearning/retrain/' + method + '/P' + str(sid) + '/'
    elif method == 'random':
        selected_channels = random.sample(range(0, Electrodes[sid]), 10)
        result_path = result_dir + 'deepLearning/retrain/' + method + '/P' + str(sid) + '/'
    print("Python: Re-train using " +str(selected_channels)+" selected channels based on " + method + " method on" + str(sid) + ".")
elif train_mode=='DA': # data augmentation
    ## TODO ad hoc
    channel_num_selected = 10
    selected_channels, acc = get_selected_channel_gumbel(sid, channel_num_selected)
    #selected_channels=False
    if method=='NI':
        print("Python: Re-train with augmentated data generated by Noise Injection.")
        selected_channels = False
        result_path = result_dir + 'deepLearning/retrain/DA_' + method + '/' + str(sid) + '/'
    elif method=='CWGANGP':
        time_stamp = time_stamps[1][cv - 1]
        ckpt_epoch = ckpt_epochs[1][cv - 1]
        print("Python: Re-train with augmentated data generated by "+method+".")
        #read_gen_data(sid, method, time_stamp, scaler='std', cv=1)
        result_path = result_dir + 'deepLearning/retrain/DA_'+method+'/'+str(sid)+'/cv'+str(cv)+'/'
        gen_data_all = read_gen_data(sid,method,time_stamp,'std',cv)  # (760, 5, 500) * 5
    elif method=='cTGAN':
        time_stamp = time_stamps[0][cv - 1]
        ckpt_epoch = ckpt_epochs[0][cv - 1]
        print("Python: Re-train with augmentated data generated by "+method+".")
        #selected_channels = False
        result_path = result_dir + 'deepLearning/retrain/DA_'+method+'/'+str(sid)+'/cv'+str(cv)+'/'
        gen_data_all = read_gen_data(sid,method,time_stamp,'std',cv)  # (760, 5, 500) * 5
    elif method=='VAE':
        time_stamp = time_stamps[2][cv - 1]
        ckpt_epoch = ckpt_epochs[2][cv - 1]
        print("Python: Re-train with augmentated data generated by "+method+".")
        #selected_channels = False
        result_path = result_dir + 'deepLearning/retrain/DA_'+method+'/'+str(sid)+'/cv'+str(cv)+'/'
        gen_data_all = read_gen_data(sid,method,time_stamp,'std',cv)  # (760, 5, 500) * 5

    else:
        print(r"Method should be one of ['NI','CWGANGP','TTSCGAN']")

    print('Retrain using data augmented by '+method+'.')
elif train_mode=='original':
    method=None
    gen_data_all=None
    selected_channels = False
    result_path = result_dir + 'deepLearning/original/sid'+str(sid) + '/cv'+str(cv)+'/'
    print("Original training.")

if not os.path.exists(result_path):
    os.makedirs(result_path)
print('Result Path: '+result_path+'.')

scaler='std' # 'std'/None
#test_epochs, val_epochs, train_epochs, scaler=read_data(sid,fs,selected_channels=selected_channels,scaler=scaler)
test_epochs, val_epochs, train_epochs, scaler=read_data_split_function(sid, fs, selected_channels=selected_channels,scaler='std',cv_idx=cv,re_referencing=True)
if method=='NI':
    std_scale=0.1 # 0.1: 0.75 how much noise added
    train_epochs_NI=noise_injection_epoch_list(train_epochs,std_scale)
    train_epochs=[np.concatenate((train_epochs[i],train_epochs_NI[i]),axis=0) for i in range(class_number)]
    gen_data_all=False
# X_train.shape: (1520, 208, 500); y_train.shape: (1520, 1);
X_train,y_train,X_val,y_val,X_test,y_test=windowed_data(train_epochs,val_epochs,test_epochs,wind,stride,
                                                        gen_data_all=gen_data_all,train_mode=train_mode,method=method)

chn_num=X_train.shape[1]

check_data_dist=False
if check_data_dist:
    train = X_train.reshape([X_train.shape[0], X_train.shape[1] * X_train.shape[2]])  # (72798, 7000)
    val = X_val.reshape([X_val.shape[0], X_val.shape[1] * X_val.shape[2]])
    test = X_test.reshape([X_test.shape[0], X_test.shape[1] * X_test.shape[2]])  # (2961, 7000)
    compare = np.concatenate((train, val, test), axis=0)
    y = [0] * train.shape[0] + [1] * val.shape[0] + [2] * test.shape[0]
    from sklearn.decomposition import PCA
    from sklearn.manifold import TSNE
    #import matplotlib.pyplot as plt

    pca_n = PCA(n_components=200)
    tsne_n = TSNE(n_components=2, verbose=0, perplexity=40, n_iter=300)

    pca_result = pca_n.fit_transform(compare)  # (10000, 784)-->(10000, 100)
    print('Cumulative explained variation for 50 principal components: {}'.format(np.sum(pca_n.explained_variance_ratio_)))
    tsne_result = tsne_n.fit_transform(pca_result)  # (10000, 50)-->(10000, 2)

    fig, ax = plt.subplots()
    ax.scatter(tsne_result[:train.shape[0], 0], tsne_result[:train.shape[0], 1])
    ax.scatter(tsne_result[train.shape[0]:train.shape[0] + val.shape[0], 0],
               tsne_result[train.shape[0]:train.shape[0] + val.shape[0], 1])
    ax.scatter(tsne_result[-test.shape[0]:, 0], tsne_result[-test.shape[0]:, 1])

train_set=myDataset(X_train,y_train)
val_set=myDataset(X_val,y_val)
test_set=myDataset(X_test,y_test)

batch_size = 32
train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, pin_memory=False)
val_loader = DataLoader(dataset=val_set, batch_size=batch_size, shuffle=True, pin_memory=False)
test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True, pin_memory=False)

train_size=len(train_loader.dataset)  #1520
val_size=len(val_loader.dataset) # 190
test_size=len(test_loader.dataset) #190

# Extract number of chans and time steps from dataset
one_window=next(iter(train_loader))[0]
n_chans = one_window.shape[1]
input_window_samples=one_window.shape[2]

#model_name='deepnet'
if model_name=='eegnet':
    #print('Here')
    net = EEGNetv4(n_chans, class_number, input_window_samples=input_window_samples, final_conv_length='auto', drop_prob=0.5)
elif model_name=='shallowFBCSPnet':
    net = ShallowFBCSPNet(n_chans,class_number,input_window_samples=input_window_samples,final_conv_length='auto',) # 51%
elif model_name=='deepnet':
    net = deepnet(n_chans,class_number,wind) # 81%
elif model_name == 'deepnet2':
    net = deepnet_seq(n_chans, class_number, wind)
elif model_name == 'deepnet_rnn':
    net = deepnet_rnn(n_chans, class_number, wind)  # 65%
elif model_name=='resnet':
    net=d2lresnet(class_num=class_number,end_with_logsoftmax=False) # 92%
elif model_name=='tsception':
    net = TSception2(1000, n_chans, 3, 3, 0.5)
elif model_name=='deepnet_da':
    net = deepnet_da(n_chans, class_number, wind)

#net = deepnet_resnet(n_chans,n_classes,input_window_samples=input_window_samples,expand=True) # 50%
#net=TSception(208)
#net=TSception(1000,n_chans,3,3,0.5)

lr = 0.01
weight_decay = 1e-10
batch_size = 32
epoch_num = 500
patients=10

img_size=[n_chans,wind]
#net = timm.create_model('visformer_tiny',num_classes=n_classes,in_chans=1,img_size=img_size)
net=net.to(device)

criterion = torch.nn.CrossEntropyLoss()
#criterion = nn.NLLLoss()
#optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9)
optimizer = torch.optim.Adadelta(net.parameters(), lr=lr)
#optimizer = torch.optim.Adam(net.parameters(), lr=lr)
# Decay LR by a factor of 0.1 every 7 epochs
lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)

train_losses=[]
train_accs=[]
val_accs=[]
reg_type= torch.FloatTensor if not torch.cuda.is_available() else torch.cuda.FloatTensor
for epoch in range(epoch_num):
    print("------ epoch" + str(epoch) + ": sid"+str(sid)+"@"+model_name+"-----")
    net.train()
    loss_epoch = 0
    reg_variable=reg_type([0])
    running_loss = 0.0
    running_corrects = 0
    for batch, (trainx, trainy) in enumerate(train_loader):
        optimizer.zero_grad()
        if (cuda):
            trainx = trainx.float().cuda()
        else:
            trainx = trainx.float()
        y_pred = net(trainx)
        #print("y_pred shape: " + str(y_pred.shape))
        preds = y_pred.argmax(dim=1, keepdim=True) # Returns the indices of the maximum value of all elements in the input tensor.
        #_, preds = torch.max(y_pred, 1)

        if cuda:
            loss = criterion(y_pred, trainy.squeeze().cuda().long())
        else:
            loss = criterion(y_pred, trainy.squeeze())

        if model_name != 'resnet':
            for i, layer in enumerate(net.layers):
                reg_variable = reg_variable+torch.sum(torch.pow(layer.weight.detach(), 2))
            reg_variable = weight_decay * reg_variable
        #print("Origin loss: "+ str(loss.item())+", regularization: "+ str(reg_variable)+".")
        loss=loss+reg_variable
        #print("New loss: " + str(loss.item()) + ".")
        loss.backward()  # calculate the gradient and store in .grad attribute.
        optimizer.step()
        running_loss += loss.item() * trainx.shape[0]
        running_corrects += torch.sum(preds.cpu().squeeze() == trainy.squeeze())
    #print("train_size: " + str(train_size))
    #lr_scheduler.step() # test it
    train_loss = running_loss / train_size
    train_acc = (running_corrects.double() / train_size).item()
    train_losses.append(train_loss)
    train_accs.append(train_acc)
    #print("Training loss: {:.2f}; Accuracy: {:.2f}.".format(train_loss,train_acc))
    #print("Training " + str(epoch) + ": loss: " + str(epoch_loss) + "," + "Accuracy: " + str(epoch_acc.item()) + ".")

    running_loss = 0.0
    running_corrects = 0
    if epoch % 1 == 0:
        net.eval()
        # print("Validating...")
        with torch.no_grad():
            for _, (val_x, val_y) in enumerate(val_loader):
                if (cuda):
                    val_x = val_x.float().cuda()
                    # val_y = val_y.float().cuda()
                else:
                    val_x = val_x.float()
                    # val_y = val_y.float()
                outputs = net(val_x)
                #_, preds = torch.max(outputs, 1)
                preds = outputs.argmax(dim=1, keepdim=True)

                running_corrects += torch.sum(preds.cpu().squeeze() == val_y.squeeze())

        val_acc = (running_corrects.double() / val_size).item()
        val_accs.append(val_acc)
        print("Training loss:{:.2f},Accuracy:{:.2f}; Evaluation accuracy:{:.2f}.".format(train_loss, train_acc,val_acc))
    if epoch==0:
        best_epoch=0
        best_acc=val_acc
        patient=patients
        state = {
            'net': net.state_dict(),
            'optimizer': optimizer.state_dict(),
            'epoch': epoch,
            # 'loss': epoch_loss
        }
    else:
        if val_acc>best_acc:
            best_epoch=epoch
            best_acc=val_acc
            patient=patients
            state = {
                'net': net.state_dict(),
                'optimizer': optimizer.state_dict(),
                'epoch': epoch,
                #'loss': epoch_loss
            }

        else:
            patient=patient-1
    print("patients left: {:d}".format(patient))
    if patient==0:
        savepath = result_path + 'checkpoint_'+model_name+'_' + str(best_epoch) + '.pth'
        torch.save(state, savepath)
        break

checkpoint = torch.load(savepath)
net.load_state_dict(checkpoint['net'])
optimizer.load_state_dict(checkpoint['optimizer'])

net.eval()
# print("Validating...")
with torch.no_grad():
    running_corrects = 0
    for _, (test_x, test_y) in enumerate(test_loader):
        if (cuda):
            test_x = test_x.float().cuda()
            # val_y = val_y.float().cuda()
        else:
            test_x = test_x.float()
            # val_y = val_y.float()
        outputs = net(test_x)
        #_, preds = torch.max(outputs, 1)
        preds = outputs.argmax(dim=1, keepdim=True)

        running_corrects += torch.sum(preds.cpu().squeeze() == test_y.squeeze())
test_acc = (running_corrects.double() / test_size).item()
print("Test accuracy: {:.2f}.".format(test_acc))

filename=result_path+'cv'+str(cv)+'.txt'
with open(filename,'w') as f:
    f.write("Test accuracy: {:.2f}.".format(test_acc))
    f.write('\n')

train_result={}
train_result['train_losses']=train_losses
train_result['train_accs']=train_accs
train_result['val_accs']=val_accs
train_result['test_acc']=test_acc

filename=result_path+'cv'+str(cv) + '.npy'
np.save(filename,train_result)

#load
#train_result = np.load(filename+'.npy',allow_pickle='TRUE').item()
#print(read_dictionary['train_losses'])

