{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### This script will segment audio recordings according to the voice activity: covert vs overt\n",
    "\n",
    "### The result can be used for a binary classification between covert vs overt.\n",
    "\n",
    "Method: detect the offset of covert/overt speech in each denoised audio trial, then use this offset to segment the EEG data."
   ],
   "id": "c9ba4ef6461489a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T19:00:08.881543Z",
     "start_time": "2024-09-03T19:00:04.217527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from speech_pinyin_Ruijin.config import *\n",
    "import glob\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pylab as plt\n",
    "import mne\n",
    "import numpy as np\n",
    "from utils.util_MNE import keep_annotation\n",
    "import itertools"
   ],
   "id": "2240a55ac757fcfc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "2024-09-04 03:00:04 - Start Program\n",
      "========================================\n",
      "\n",
      "pre_all: Running from CMD.\n",
      "common_dl.py: Using CUDA.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T02:34:26.608467Z",
     "start_time": "2024-09-04T02:34:26.594860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sid=1\n",
    "folder=data_dir+str(sid)+'-*'\n",
    "folder=os.path.normpath(glob.glob(folder)[0])\n",
    "folder=folder.replace(\"\\\\\", \"/\")\n",
    "audio_folder=folder+'/raw/matlab/result/'\n",
    "files=['name_202408280901','name_202408280930','name_202408280959']\n",
    "session=3"
   ],
   "id": "fedc6613a3d94714",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T02:43:33.307547Z",
     "start_time": "2024-09-04T02:43:33.267500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# read the denoised audio and its length\n",
    "filename=folder+'/processed/session'+str(session)+'_audio_length_in_sample.npy' # length\n",
    "lengths=np.load(filename, allow_pickle=True)\n",
    "filename=folder+'/processed/session'+str(session)+'_clean_audio_padded_denoised.wav' # denoised audio\n",
    "sf_audio,audio=wavfile.read(filename)"
   ],
   "id": "cdf6cd2c718cf1be",
   "outputs": [],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T02:43:34.351039Z",
     "start_time": "2024-09-04T02:43:34.345862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_sample(index): # index: 0-->143.\n",
    "    if index==0:\n",
    "        start=0\n",
    "    else:\n",
    "        start=sum(lengths[:index])\n",
    "    end=start+lengths[index]\n",
    "    return start,end"
   ],
   "id": "48b7741352164a3b",
   "outputs": [],
   "execution_count": 128
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Check the data and try different methods to find the voicing threshold",
   "id": "b63062d011ac60fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T02:35:40.852386Z",
     "start_time": "2024-09-04T02:35:40.847127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start,end=get_sample(143) # get the 17th audio trial index\n",
    "trial=audio[start:end]"
   ],
   "id": "db879f41285bbac9",
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T02:35:41.969155Z",
     "start_time": "2024-09-04T02:35:41.867175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%matplotlib qt\n",
    "plt.plot(trial)"
   ],
   "id": "6305c6068c45e5f2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23838b3cb00>]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Zoom in the transition region:\n",
    "\n",
    "![](img\\8.png)\n",
    "\n",
    "Further zoom in, it shows high frequency power increases:\n",
    "\n",
    "![](img\\9.png)\n",
    "\n",
    "According to Google, man voice concentrate around 120Hz, but Adacity produces below spectrogram for a trial:\n",
    "\n",
    "![](img\\10.png)\n",
    "\n",
    "Extract high frequency component and use it as marker should be a better solution. But, for now, I can tolerate some mis-alignment.\n"
   ],
   "id": "cfffb5df7fe1ba92"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T02:36:23.724471Z",
     "start_time": "2024-09-04T02:36:17.275033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from speech_Dutch.baseline_linear_regression.extract_features import hilbert3\n",
    "import scipy\n",
    "sr=48000\n",
    "# Linear detrend\n",
    "data = scipy.signal.detrend(audio, axis=0)  # low frequency trend\n",
    "# Extract 90-130 Hz\n",
    "sos = scipy.signal.iirfilter(4, [90 / (sr / 2), 130 / (sr / 2)], btype='bandpass', output='sos')\n",
    "data = scipy.signal.sosfiltfilt(sos, data, axis=0)  # (307511, 127)\n",
    "data_env = np.abs(hilbert3(data)) # (307523, 127)"
   ],
   "id": "9099d63217287091",
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T02:36:26.282865Z",
     "start_time": "2024-09-04T02:36:26.151009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start,end=get_sample(16) # get the 17th audio trial index\n",
    "plt.plot(data[start:end])\n",
    "plt.plot(data_env[start:end])"
   ],
   "id": "650dcfd2b0e7b2fa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23838bfd0a0>]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Extrac 90-130hz is not a good idea\n",
    "\n",
    "![](img\\11.png)"
   ],
   "id": "2761551a4b73eee4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T00:51:57.421129Z",
     "start_time": "2024-09-04T00:51:57.324779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# use the MNE method\n",
    "ch_types = ['eeg']\n",
    "ch_names = ['audio']\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=sr, ch_types=ch_types)\n",
    "raw = mne.io.RawArray(audio[np.newaxis,:], info)"
   ],
   "id": "5d5c47d0f70f4293",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T01:02:07.769257Z",
     "start_time": "2024-09-04T01:02:00.102600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data2=raw.filter(90,130).get_data().squeeze().tolist() # (1, 40720882)\n",
    "data_env2 = np.abs(hilbert3(data2))  "
   ],
   "id": "888e5d436471eff7",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T01:02:25.655850Z",
     "start_time": "2024-09-04T01:02:25.535639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.plot(data2[start:end])\n",
    "plt.plot(data_env2[start:end])"
   ],
   "id": "7a8d667f986bb3d2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23836d4a390>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# same as previous methods:\n",
    "\n",
    "![](img\\12.png)"
   ],
   "id": "1e5f23aca1c32dc5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T02:44:22.257472Z",
     "start_time": "2024-09-04T02:44:18.212537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# work on the raw audio directly\n",
    "# Linear detrend\n",
    "sos = scipy.signal.iirfilter(4, [10 / (sr / 2)], btype='highpass', output='sos')\n",
    "tmp = scipy.signal.sosfiltfilt(sos, audio, axis=0)  # (307511, 127)\n",
    "#tmp = scipy.signal.detrend(audio, axis=0)  # low frequency trend\n",
    "audio_env = np.abs(hilbert3(tmp)) # (307523, 127)"
   ],
   "id": "5493d232aef98999",
   "outputs": [],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T02:37:11.333831Z",
     "start_time": "2024-09-04T02:37:11.187080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.plot(tmp[start:end])\n",
    "plt.plot(audio_env[start:end])"
   ],
   "id": "874c9fc709db9c31",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23838cc6930>]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 116
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Looking good. A simple threshold method can be used:\n",
    "\n",
    "![](img\\13.png)"
   ],
   "id": "cf17a4689708a27a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Extract intervals",
   "id": "3abf9e426c9e19d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T02:46:58.206342Z",
     "start_time": "2024-09-04T02:46:58.163094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# read the denoised audio and its length\n",
    "filename=folder+'/processed/session'+str(session)+'_audio_length_in_sample.npy' # length\n",
    "lengths=np.load(filename, allow_pickle=True)\n",
    "filename=folder+'/processed/session'+str(session)+'_clean_audio_padded_denoised.wav' # denoised audio\n",
    "sf_audio,audio=wavfile.read(filename)"
   ],
   "id": "8189d3e22060af45",
   "outputs": [],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T02:47:04.176596Z",
     "start_time": "2024-09-04T02:46:59.979607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# work on the raw audio directly\n",
    "# Linear detrend\n",
    "sos = scipy.signal.iirfilter(4, [10 / (sr / 2)], btype='highpass', output='sos')\n",
    "tmp = scipy.signal.sosfiltfilt(sos, audio, axis=0)  # (307511, 127)\n",
    "#tmp = scipy.signal.detrend(audio, axis=0)  # low frequency trend\n",
    "audio_env = np.abs(hilbert3(tmp)) # (307523, 127)"
   ],
   "id": "48ca39cb40247b40",
   "outputs": [],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T03:04:05.773097Z",
     "start_time": "2024-09-04T03:04:02.263642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import copy\n",
    "threshold=50\n",
    "marker=max(audio)\n",
    "starts=[]\n",
    "ends=[]\n",
    "trial_list_VAD=[]\n",
    "for i in range(144):\n",
    "    #if i >0: # discard the first trial\n",
    "    start,end=get_sample(i) # get the 17th audio trial index\n",
    "    trial=copy.deepcopy(audio[start:end])\n",
    "    trial_env=audio_env[start:end]\n",
    "    if i==0:\n",
    "        start1=116500/48000\n",
    "        start2=start1+0.7\n",
    "        end1=188400/48000\n",
    "        end2=end1-0.7\n",
    "    if i>0:\n",
    "        start1=0.7\n",
    "        start2=2.8\n",
    "        end1=2.8\n",
    "        end2=0.7\n",
    "    for j in range(int(start1*48000),int(start2*48000)):\n",
    "        if trial_env[j]>threshold:\n",
    "            starts.append(j)\n",
    "            trial[j]=marker\n",
    "            break\n",
    "    for k in range(int(end1*48000),int(end2*48000),-1):\n",
    "        if trial_env[k]>threshold:\n",
    "            ends.append(k)\n",
    "            trial[k]=marker\n",
    "            break\n",
    "    trial_list_VAD.append(trial)\n"
   ],
   "id": "8b23a953a89c2b50",
   "outputs": [],
   "execution_count": 158
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T03:04:08.391627Z",
     "start_time": "2024-09-04T03:04:08.242793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sanity check\n",
    "ind=27\n",
    "plt.plot(audio_env[get_sample(ind)[0]:get_sample(ind)[1]])\n",
    "plt.plot(audio[get_sample(ind)[0]:get_sample(ind)[1]])"
   ],
   "id": "bf178ef0a7d994f8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2383ac4da00>]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 159
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T03:04:23.670093Z",
     "start_time": "2024-09-04T03:04:19.024905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "audio_VAD=np.asarray(list(itertools.chain(*trial_list_VAD)))\n",
    "print(len(audio_VAD)/48000) #ceil:842.3416666666667  #floor: 842.3388125  EEG: first trial + 835.21=842.376\n",
    "filename=folder+'/processed/session'+str(session)+'_audio_VAD.wav'\n",
    "wavfile.write(filename,48000,audio_VAD)"
   ],
   "id": "d61fa625b34d8cf2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848.3517083333334\n"
     ]
    }
   ],
   "execution_count": 160
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T03:04:25.336045Z",
     "start_time": "2024-09-04T03:04:25.233041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ind=27\n",
    "plt.plot(audio_env[get_sample(ind)[0]:get_sample(ind)[1]])\n",
    "plt.plot(audio_VAD[get_sample(ind)[0]:get_sample(ind)[1]])"
   ],
   "id": "fa24b2ed53777c92",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2383acfbce0>]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 161
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Looking good to me:\n",
    "\n",
    "![](img\\14.png)\n",
    "\n",
    "![](img\\15.png)"
   ],
   "id": "d08ed2404d4123e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T03:04:31.020111Z",
     "start_time": "2024-09-04T03:04:31.014397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(starts))\n",
    "print(len(ends))"
   ],
   "id": "fa2d10078cf1e3df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "144\n"
     ]
    }
   ],
   "execution_count": 162
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T03:19:52.026123Z",
     "start_time": "2024-09-04T03:19:52.021293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result=[[i,j] for i,j in zip(starts,ends)]\n",
    "filename=folder+'/processed/session'+str(session)+'_audio_VAD.npy'\n",
    "np.save(filename, np.array(result, dtype=object), allow_pickle=True)"
   ],
   "id": "ceb6d27171aa2682",
   "outputs": [],
   "execution_count": 167
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bci",
   "language": "python",
   "name": "bci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
